\section{Abstract}
Dense trajectories from 2D videos have been demonstrated state-of-the-art at action recognition that can capture most discriminative motions.
In this work, we propose the similar approach in depth video and show its effectiveness on action recognition.
We extract dense trajectories from 2D videos transformed from depth video and apply trajectory-aligned descriptors to calculate motion features.
Further, we present a projection method to view actions under different directions that provide additional information for recognizing actions more exactly.
We evaluate this approach on framework of action recognition using the benchmark MSR Action 3D and MSR Activity Daily 3D datasets.
Evaluation results show that our proposed approach is effective for action recognition on depth video and outperforms the state-of-the-art methods.
